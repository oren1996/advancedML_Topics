{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxEMakEiBTl-"
   },
   "source": [
    "#Final-term exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63MGm65eCjRr"
   },
   "source": [
    "#1. Load your libraries here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ug3u-V4-BWTi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/orenelbazis/anaconda3/envs/nlp_env/lib/python3.9/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/orenelbazis/anaconda3/envs/nlp_env/lib/python3.9/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/orenelbazis/anaconda3/envs/nlp_env/lib/python3.9/site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/orenelbazis/anaconda3/envs/nlp_env/lib/python3.9/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/orenelbazis/anaconda3/envs/nlp_env/lib/python3.9/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/orenelbazis/anaconda3/envs/nlp_env/lib/python3.9/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 17:32:45.609901: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Part 3\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Part 4\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Part 5\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Part 6\n",
    "%pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Part 7\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Part 8\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Part 9\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "# Part 10\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Part 11\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Part 12\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Part 13\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Part 15\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cHQNXM3l8L9"
   },
   "source": [
    "#Part A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoS_ee5wDJDE"
   },
   "source": [
    "#Upload your data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_g0XLs7MDKQE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Final Weight</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>capital loss</th>\n",
       "      <th>Hours per Week</th>\n",
       "      <th>Native Country</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age          Workclass  Final Weight   Education  EducationNum  \\\n",
       "0   39          State-gov         77516   Bachelors            13   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors            13   \n",
       "2   38            Private        215646     HS-grad             9   \n",
       "3   53            Private        234721        11th             7   \n",
       "4   28            Private        338409   Bachelors            13   \n",
       "\n",
       "        Marital Status          Occupation    Relationship    Race   Gender  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   Capital Gain  capital loss  Hours per Week  Native Country  Income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here:\n",
    "# Link to the dataset: https://www.kaggle.com/datasets/tawfikelmetwally/census-income-dataset/data?select=adult.csv\n",
    "\n",
    "classification_df = pd.read_csv(\"data_for_classification/adult.csv\")\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mO-FSmz3DTAj"
   },
   "source": [
    "#2. Read the file into a pandas data frame:\n",
    "Split your data to:\n",
    "\n",
    "a. X: the feature matrix\n",
    "\n",
    "b. y: the label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0-ydbL4lDXIa"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "X_classification = classification_df.drop(columns=['Income'])  \n",
    "y_classification = classification_df['Income'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5BZb-AnDXnb"
   },
   "source": [
    "#3.A. Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "glKyIdt4DcKz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null values: Age               0\n",
      "Workclass         0\n",
      "Final Weight      0\n",
      "Education         0\n",
      "EducationNum      0\n",
      "Marital Status    0\n",
      "Occupation        0\n",
      "Relationship      0\n",
      "Race              0\n",
      "Gender            0\n",
      "Capital Gain      0\n",
      "capital loss      0\n",
      "Hours per Week    0\n",
      "Native Country    0\n",
      "Income            0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 24\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "print(f'Number of Null values: {classification_df.isnull().sum()}')\n",
    "\n",
    "# I also checked for duplicates values and found 0 duplicates\n",
    "print(f'Number of Duplicated values: {classification_df.duplicated().sum()}')\n",
    "\n",
    "# Drop duplicates and keep only the first occurrence\n",
    "classification_df = classification_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYqhzgE8Dkdj"
   },
   "source": [
    "If there are no missing values in your data, follow the next steps:\n",
    "1. uncomment the following function by:\n",
    "\n",
    "  a. selecting all the code in the chunk\n",
    "\n",
    "  b. pressing \"ctrl\"+\"/\" to uncomment all lines\n",
    "2. assign the missing values-containing data to a new variable name (see example below).\n",
    "\n",
    "Say my dataset features is named X.\n",
    "\n",
    "Than the use of the function would be:\n",
    "\n",
    "\n",
    "```\n",
    "X_missing=add_missing_values(X)\n",
    " ```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l8vxkVPpDip8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               1742\n",
       "Workclass         1770\n",
       "Final Weight      1770\n",
       "Education         1735\n",
       "EducationNum      1804\n",
       "Marital Status    1718\n",
       "Occupation        1645\n",
       "Relationship      1764\n",
       "Race              1675\n",
       "Gender            1721\n",
       "Capital Gain      1776\n",
       "capital loss      1758\n",
       "Hours per Week    1744\n",
       "Native Country    1798\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_missing_values(X_full):\n",
    "    import numpy as np\n",
    "    Col_names=X_full.columns\n",
    "    X_full=X_full.to_numpy()\n",
    "    rng = np.random.RandomState(4)\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    X_missing=pd.DataFrame(X_missing)\n",
    "    X_missing.columns=Col_names\n",
    "    return X_missing\n",
    "\n",
    "X_missing = add_missing_values(X_classification)\n",
    "X_missing.isnull().sum()"
   ]
  },
  {
   "metadata": {
    "id": "vZLGvx7YIUCc"
   },
   "cell_type": "code",
   "execution_count": 6,
   "source": "#your code here, if there are no missing values:",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNhwID7JGHQz"
   },
   "source": [
    "\n",
    "#3.B. Impute the missing values using two different methods and assign the imputed output datasets into variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             30819 non-null  float64\n",
      " 1   Workclass       30791 non-null  object \n",
      " 2   Final Weight    30791 non-null  float64\n",
      " 3   Education       30826 non-null  object \n",
      " 4   EducationNum    30757 non-null  float64\n",
      " 5   Marital Status  30843 non-null  object \n",
      " 6   Occupation      30916 non-null  object \n",
      " 7   Relationship    30797 non-null  object \n",
      " 8   Race            30886 non-null  object \n",
      " 9   Gender          30840 non-null  object \n",
      " 10  Capital Gain    30785 non-null  float64\n",
      " 11  capital loss    30803 non-null  float64\n",
      " 12  Hours per Week  30817 non-null  float64\n",
      " 13  Native Country  30763 non-null  object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# The function add_missing_values change the data type of the columns to object,\n",
    "# so we need to change it back to their original data type\n",
    "\n",
    "# List of columns that are supposed to be numeric\n",
    "numeric_columns = ['Age', 'Final Weight', 'EducationNum', 'Capital Gain', 'capital loss', 'Hours per Week']\n",
    "\n",
    "# Convert columns to float to preserve NaN values and after inputing we will convert them back to int\n",
    "X_missing[numeric_columns] = X_missing[numeric_columns].apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "\n",
    "# Check the data types to confirm\n",
    "X_missing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nQDXRX4TIotK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the filled dataset with the first method:  0\n",
      "Number of missing values in the filled dataset with the second method:  0\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "\n",
    "# Capture the original column order\n",
    "original_columns_order = X_missing.columns\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = X_missing.select_dtypes(include=['float64']).columns\n",
    "categorical_cols = X_missing.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 1) First Method using SimpleImputer for Numerical and Categorical Columns:\n",
    "\n",
    "# Impute missing values for numerical columns using mean strategy\n",
    "imr_mean = SimpleImputer(strategy='mean')\n",
    "X_classification_filled_mean_numerical = pd.DataFrame(imr_mean.fit_transform(X_missing[numerical_cols]), columns=numerical_cols)\n",
    "\n",
    "# Impute missing values for categorical columns using most frequent strategy\n",
    "imr_mode = SimpleImputer(strategy='most_frequent')\n",
    "X_classification_filled_mode_categorical = pd.DataFrame(imr_mode.fit_transform(X_missing[categorical_cols]), columns=categorical_cols)\n",
    "\n",
    "# Combine the imputed numerical and categorical columns\n",
    "X_classification_first = pd.concat([X_classification_filled_mean_numerical, X_classification_filled_mode_categorical], axis=1)\n",
    "\n",
    "# Reorder the columns to match the original order\n",
    "X_classification_first = X_classification_first[original_columns_order]\n",
    "\n",
    "# Check for remaining missing values and display the first few rows\n",
    "print('Number of missing values in the filled dataset with the first method: ', X_classification_first.isnull().sum().sum())\n",
    "\n",
    "# 2) Second Method using KNNImputer for Numerical Columns and SimpleImputer for Categorical Columns:\n",
    "\n",
    "# Impute numeric columns using KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=10, weights='distance')\n",
    "X_missing_numeric = pd.DataFrame(knn_imputer.fit_transform(X_missing[numerical_cols]), columns=numerical_cols)\n",
    "\n",
    "# Impute categorical columns using SimpleImputer with 'most_frequent' strategy\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "X_missing_categorical = pd.DataFrame(imputer_categorical.fit_transform(X_missing[categorical_cols]), columns=categorical_cols)\n",
    "\n",
    "# Combine numeric and categorical columns back into a single DataFrame\n",
    "X_classification_second = pd.concat([X_missing_numeric, X_missing_categorical], axis=1)\n",
    "\n",
    "# Verify no missing values remain\n",
    "print('Number of missing values in the filled dataset with the second method: ', X_classification_second.isnull().sum().sum())\n",
    "\n",
    "# Reorder the columns to match the original order\n",
    "X_classification_second = X_classification_second[original_columns_order]\n",
    "\n",
    "# Comverting back to original data types\n",
    "# List of columns that should be integers\n",
    "numeric_columns = ['Age', 'Final Weight', 'EducationNum', 'Capital Gain', 'capital loss', 'Hours per Week']\n",
    "\n",
    "# Convert the float64 columns back to int64 after imputation\n",
    "X_classification_first[numeric_columns] = X_classification_first[numeric_columns].astype(int)\n",
    "X_classification_second[numeric_columns] = X_classification_second[numeric_columns].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAEMq4hijF84"
   },
   "source": [
    "#3.C. Convert categorical features to dummy variables if number of categories is lower than 5, otherwise remove from data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9FGOXjHHjYHw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values in 'Workclass': 9\n",
      "Column 'Workclass' has more than 4 categories and should be removed.\n",
      "Distinct values in 'Education': 16\n",
      "Column 'Education' has more than 4 categories and should be removed.\n",
      "Distinct values in 'Marital Status': 7\n",
      "Column 'Marital Status' has more than 4 categories and should be removed.\n",
      "Distinct values in 'Occupation': 15\n",
      "Column 'Occupation' has more than 4 categories and should be removed.\n",
      "Distinct values in 'Relationship': 6\n",
      "Column 'Relationship' has more than 4 categories and should be removed.\n",
      "Distinct values in 'Race': 5\n",
      "Column 'Race' has more than 4 categories and should be removed.\n",
      "Distinct values in 'Gender': 2\n",
      "Column 'Gender' has 4 or fewer categories and can be converted to dummy variables.\n",
      "Distinct values in 'Native Country': 42\n",
      "Column 'Native Country' has more than 4 categories and should be removed.\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "# Both dataframes X_classification_first and X_classification_second come from the same dataframe and \n",
    "# therefore have the same columns (because we did not drop any column).\n",
    "\n",
    "# Iterate through categorical columns and count distinct values\n",
    "columns_to_remove = []\n",
    "for col in categorical_cols:\n",
    "    unique_values = X_missing[col].nunique()\n",
    "    print(f\"Distinct values in '{col}': {unique_values}\")\n",
    "    \n",
    "    # Check if the column has more than 4 categories\n",
    "    if unique_values > 4:\n",
    "        print(f\"Column '{col}' has more than 4 categories and should be removed.\")\n",
    "        columns_to_remove.append(col)\n",
    "    else:\n",
    "        print(f\"Column '{col}' has 4 or fewer categories and can be converted to dummy variables.\")\n",
    "\n",
    "# Drop the columns with more than 4 categories\n",
    "X_cleaned_first_classification = X_classification_first.drop(columns=columns_to_remove)\n",
    "X_cleaned_second_classification = X_classification_second.drop(columns=columns_to_remove)\n",
    "\n",
    "# Convert remaining categorical columns (with 4 or fewer categories) to dummy variables\n",
    "X_cleaned_first_classification = pd.get_dummies(X_cleaned_first_classification, drop_first=True)\n",
    "X_cleaned_second_classification = pd.get_dummies(X_cleaned_second_classification, drop_first=True)\n",
    "\n",
    "# Step 4: Convert float64 columns back to int64 for numerical columns after imputation\n",
    "X_cleaned_first_classification[numeric_columns] = X_cleaned_first_classification[numeric_columns].astype(int)\n",
    "X_cleaned_second_classification[numeric_columns] = X_cleaned_second_classification[numeric_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Final Weight</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>capital loss</th>\n",
       "      <th>Hours per Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.539725</td>\n",
       "      <td>1.896873e+05</td>\n",
       "      <td>10.079512</td>\n",
       "      <td>1088.824883</td>\n",
       "      <td>87.143270</td>\n",
       "      <td>40.396425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.253988</td>\n",
       "      <td>1.029162e+05</td>\n",
       "      <td>2.500277</td>\n",
       "      <td>7255.306415</td>\n",
       "      <td>391.407039</td>\n",
       "      <td>11.971641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.209330e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.838020e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.315730e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age  Final Weight  EducationNum  Capital Gain  capital loss  \\\n",
       "count  32561.000000  3.256100e+04  32561.000000  32561.000000  32561.000000   \n",
       "mean      38.539725  1.896873e+05     10.079512   1088.824883     87.143270   \n",
       "std       13.253988  1.029162e+05      2.500277   7255.306415    391.407039   \n",
       "min       17.000000  1.228500e+04      1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.209330e+05      9.000000      0.000000      0.000000   \n",
       "50%       38.000000  1.838020e+05     10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.315730e+05     12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06     16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       Hours per Week  \n",
       "count    32561.000000  \n",
       "mean        40.396425  \n",
       "std         11.971641  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned_first_classification.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Final Weight</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>capital loss</th>\n",
       "      <th>Hours per Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.555972</td>\n",
       "      <td>1.895822e+05</td>\n",
       "      <td>10.060440</td>\n",
       "      <td>1085.870612</td>\n",
       "      <td>88.045269</td>\n",
       "      <td>40.412702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.356819</td>\n",
       "      <td>1.033363e+05</td>\n",
       "      <td>2.530618</td>\n",
       "      <td>7339.826176</td>\n",
       "      <td>396.259958</td>\n",
       "      <td>12.101955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.202770e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.795080e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.339930e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age  Final Weight  EducationNum  Capital Gain  capital loss  \\\n",
       "count  32561.000000  3.256100e+04  32561.000000  32561.000000  32561.000000   \n",
       "mean      38.555972  1.895822e+05     10.060440   1085.870612     88.045269   \n",
       "std       13.356819  1.033363e+05      2.530618   7339.826176    396.259958   \n",
       "min       17.000000  1.228500e+04      1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.202770e+05      9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.795080e+05     10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.339930e+05     12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06     16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       Hours per Week  \n",
       "count    32561.000000  \n",
       "mean        40.412702  \n",
       "std         12.101955  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned_second_classification.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on both df the values seems fine even for the columns Capitail Gain or capital loss where the min is 0 because we are talking about a gain/loss of money so it could definitely be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqsoO5XOjaqd"
   },
   "source": [
    "#4. Train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5v_IudXzjaYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size (first): (26048, 7), (26048,)\n",
      "Test set size (first): (6513, 7), (6513,)\n",
      "Train set size (second): (26048, 7), (26048,)\n",
      "Test set size (second): (6513, 7), (6513,)\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "\n",
    "# 1) First Imputed Dataset:\n",
    "# Split the first cleaned dataset (X_cleaned_first) and target variable (y_classification)\n",
    "X_train_first_classification, X_test_first_classification, y_train_first_classification, y_test_first_classification = train_test_split(\n",
    "    X_cleaned_first_classification, y_classification, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the sizes to confirm\n",
    "print(f\"Train set size (first): {X_train_first_classification.shape}, {y_train_first_classification.shape}\")\n",
    "print(f\"Test set size (first): {X_test_first_classification.shape}, {y_test_first_classification.shape}\")\n",
    "\n",
    "\n",
    "# 2) Second Imputed Dataset:\n",
    "# Split the second cleaned dataset (X_cleaned_second) and target variable (y_classification)\n",
    "X_train_second_classification, X_test_second_classification, y_train_second_classification, y_test_second_classification = train_test_split(\n",
    "    X_cleaned_second_classification, y_classification, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the sizes to confirm\n",
    "print(f\"Train set size (second): {X_train_second_classification.shape}, {y_train_second_classification.shape}\")\n",
    "print(f\"Test set size (second): {X_test_second_classification.shape}, {y_test_second_classification.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdbJRpF8IsY8"
   },
   "source": [
    "#5. Preprocessing (for both imputed datasets): <br>\n",
    "a. standardize or normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wzahU-AlJV3c"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "#5.a\n",
    "# Create a StandardScaler object\n",
    "scaler_first = StandardScaler()\n",
    "scaler_second = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test sets\n",
    "# For First Imputed Dataset\n",
    "X_train_first_scaled_classification = scaler_first.fit_transform(X_train_first_classification)\n",
    "X_test_first_scaled_classification = scaler_first.transform(X_test_first_classification)\n",
    "\n",
    "# For Second Imputed Dataset\n",
    "X_train_second_scaled_classification = scaler_second.fit_transform(X_train_second_classification)\n",
    "X_test_second_scaled_classification = scaler_second.transform(X_test_second_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. print visual representation of the y variable (the output/label variable) or/and value counts of the two categories to test if the data is imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income\n",
      "<=50K    19778\n",
      ">50K      6270\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income\n",
      "<=50K    19778\n",
      ">50K      6270\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "#5.b\n",
    "\n",
    "# 1) First Imputed Dataset\n",
    "# Plot the value counts of the target variable (y_train_first) for imbalance check\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y_train_first_classification)\n",
    "plt.title('Distribution of Target Variable (y_train_first)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print the value counts to check for imbalance\n",
    "print(y_train_first_classification.value_counts())\n",
    "\n",
    "# 2) Second Imputed Dataset\n",
    "# Plot the value counts of the target variable (y_train_second) for imbalance check\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y_train_second_classification)\n",
    "plt.title('Distribution of Target Variable (y_train_second)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print the value counts to check for imbalance\n",
    "print(y_train_second_classification.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Pr9C1CLnlL"
   },
   "source": [
    "#6. Choose one balancing method and perform it on your data.\n",
    "\n",
    "Verbally explain the logic behind the chosen balancing metohd, how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WTtWHavyMF5S"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for y_train_first_balanced:\n",
      "Income\n",
      ">50K     19778\n",
      "<=50K    19778\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for y_train_second_balanced:\n",
      "Income\n",
      ">50K     19778\n",
      "<=50K    19778\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#your code here, if balancing is requierd:\n",
    "\n",
    "# 1) First Imputed Dataset\n",
    "# Create an instance of SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_first_balanced_classification, y_train_first_balanced_classification = smote.fit_resample(X_train_first_scaled_classification, y_train_first_classification)\n",
    "\n",
    "# Visualize the new balanced dataset\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y_train_first_balanced_classification)\n",
    "plt.title('Balanced Distribution of Target Variable (y_train_first_balanced)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print the value counts of the balanced dataset\n",
    "print(\"Value counts for y_train_first_balanced:\")\n",
    "print(y_train_first_balanced_classification.value_counts())\n",
    "\n",
    "# 2) Second Imputed Dataset\n",
    "# Create an instance of SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_second_balanced_classification, y_train_second_balanced_classification = smote.fit_resample(X_train_second_scaled_classification, y_train_second_classification)\n",
    "\n",
    "# Visualize the new balanced dataset\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y_train_second_balanced_classification)\n",
    "plt.title('Balanced Distribution of Target Variable (y_train_second_balanced)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print the value counts of the balanced dataset\n",
    "print(\"Value counts for y_train_second_balanced:\")\n",
    "print(y_train_second_balanced_classification.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B1KVYl3LYTM"
   },
   "source": [
    "#Your answer here: <br>\n",
    "Balancing the data was necessary because the dataset was imbalanced (for 'Income' = '<=50K': 19778 values\n",
    "and for 'Income' = '>50K': 6270 values), which can bias the model for predicting the class majority class. We chose SMOTE because it generates synthetic samples for the minority class and therefor avoid overfitting that can occur with simple duplication. The SMOTE method ensures that the minority class is represented enough and therefore it improve the model's overall performance. SMOTE is effective when we have an imbalance data and when preventing overfitting is a priority.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p32CMu4SNEQb"
   },
   "source": [
    "#7. Training models (for both imputed datasets): <br>\n",
    "**a.** choose three classification algorithms, two must be either random forest or XGBoost or catboost or LGBM, and apply the algorithms on the train set.  <br>\n",
    "\n",
    "**b.** apply hyperparameter tuning on at least two algorithms using gridsearchCV function.<br>\n",
    "\n",
    "**c.** print the best hyperparameters for the three models.\n",
    "\n",
    "Reminder, if the tuned model is named \"grid\" than to get the best hyperparameter combination use the following function:\n",
    "\n",
    "\n",
    "```\n",
    "grid.best_params_\n",
    "```\n",
    "\n",
    "\n",
    "**d.** Veraverbally explain: what is the role of the chosen hyperparmeters in the learning algorithms? How did you choose the values for the optimization? (in 3-4 lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WLveUiA9Y7Iz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest (first): {'max_depth': None, 'n_estimators': 200}\n",
      "Best parameters for XGBoost (first): {'max_depth': 6, 'n_estimators': 200}\n",
      "Best parameters for HistGradientBoostingClassifier (first): {'max_depth': 6, 'max_iter': 200}\n",
      "Best parameters for Random Forest (second): {'max_depth': None, 'n_estimators': 200}\n",
      "Best parameters for XGBoost (second): {'max_depth': 6, 'n_estimators': 200}\n",
      "Best parameters for HistGradientBoostingClassifier (second): {'max_depth': 6, 'max_iter': 200}\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder_first = LabelEncoder()\n",
    "label_encoder_second = LabelEncoder()\n",
    "\n",
    "# Convert the target variable y_train and y_test to numeric values\n",
    "y_train_first_encoded_classification = label_encoder_first.fit_transform(y_train_first_balanced_classification)\n",
    "y_test_first_encoded_classification = label_encoder_first.transform(y_test_first_classification)\n",
    "\n",
    "# Convert the target variable y_train and y_test to numeric values\n",
    "y_train_second_encoded_classification = label_encoder_second.fit_transform(y_train_second_balanced_classification)\n",
    "y_test_second_encoded_classification = label_encoder_second.transform(y_test_second_classification)\n",
    "\n",
    "\n",
    "# 7.a\n",
    "# Parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "}\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6],\n",
    "}\n",
    "\n",
    "# Parameter grid for HistGradientBoostingClassifier\n",
    "hgb_param_grid = {\n",
    "    'max_iter': [100, 200],\n",
    "    'max_depth': [3, 6]\n",
    "}\n",
    "\n",
    "# 7.a - For the first dataset\n",
    "# Create Random Forest model for the first dataset\n",
    "rf_first = RandomForestClassifier(random_state=42)\n",
    "rf_grid_first = GridSearchCV(estimator=rf_first, param_grid=rf_param_grid, cv=3)\n",
    "rf_grid_first.fit(X_train_first_balanced_classification, y_train_first_encoded_classification)\n",
    "\n",
    "# Create XGBoost model for the first dataset\n",
    "xgb_first = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "xgb_grid_first = GridSearchCV(estimator=xgb_first, param_grid=xgb_param_grid, cv=3)\n",
    "xgb_grid_first.fit(X_train_first_balanced_classification, y_train_first_encoded_classification)\n",
    "\n",
    "# Create HistGradientBoostingClassifier model for the first dataset\n",
    "hgb_first = HistGradientBoostingClassifier(random_state=42)\n",
    "hgb_grid_first = GridSearchCV(estimator=hgb_first, param_grid=hgb_param_grid, cv=3)\n",
    "hgb_grid_first.fit(X_train_first_balanced_classification, y_train_first_encoded_classification)\n",
    "\n",
    "# Best parameters for the first dataset models\n",
    "print(\"Best parameters for Random Forest (first):\", rf_grid_first.best_params_)\n",
    "print(\"Best parameters for XGBoost (first):\", xgb_grid_first.best_params_)\n",
    "print(\"Best parameters for HistGradientBoostingClassifier (first):\", hgb_grid_first.best_params_)\n",
    "\n",
    "\n",
    "# 7.b - For the second dataset\n",
    "# Create Random Forest model for the second dataset\n",
    "rf_second = RandomForestClassifier(random_state=42)\n",
    "rf_grid_second = GridSearchCV(estimator=rf_second, param_grid=rf_param_grid, cv=3)\n",
    "rf_grid_second.fit(X_train_second_balanced_classification, y_train_second_encoded_classification)\n",
    "\n",
    "# Create XGBoost model for the second dataset\n",
    "xgb_second = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "xgb_grid_second = GridSearchCV(estimator=xgb_second, param_grid=xgb_param_grid, cv=3)\n",
    "xgb_grid_second.fit(X_train_second_balanced_classification, y_train_second_encoded_classification)\n",
    "\n",
    "# Create HistGradientBoostingClassifier model for the second dataset\n",
    "hgb_second = HistGradientBoostingClassifier(random_state=42)\n",
    "hgb_grid_second = GridSearchCV(estimator=hgb_second, param_grid=hgb_param_grid, cv=3)\n",
    "hgb_grid_second.fit(X_train_second_balanced_classification, y_train_second_encoded_classification)\n",
    "\n",
    "# Best parameters for the second dataset models\n",
    "print(\"Best parameters for Random Forest (second):\", rf_grid_second.best_params_)\n",
    "print(\"Best parameters for XGBoost (second):\", xgb_grid_second.best_params_)\n",
    "print(\"Best parameters for HistGradientBoostingClassifier (second):\", hgb_grid_second.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Random Forest, n_estimators controls the number of trees in the forest which affect accuracy and computation time,max_depth limits the tree depth which allow a blance between complexity and overfitting risk. For XGBoost, learning_rate manages how much each tree contributes where smaller values reduce overfitting but require more trees, and n_estimators defines the number of boosting rounds. In HistGradientBoostingClassifier, max_iter determines the number of boosting iterations, and learning_rate affects the speed of learning and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySInCwHzY6kG"
   },
   "source": [
    "#Your answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbNQJ0fakULJ"
   },
   "source": [
    "#8. Train a neural network on both imputed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Bm7OJaGWkT0W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 2ms/step - accuracy: 0.7448 - loss: 0.5228 - val_accuracy: 0.6429 - val_loss: 0.6703\n",
      "Epoch 2/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7766 - loss: 0.4537 - val_accuracy: 0.6576 - val_loss: 0.6373\n",
      "Epoch 3/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7802 - loss: 0.4530 - val_accuracy: 0.6704 - val_loss: 0.6035\n",
      "Epoch 4/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7820 - loss: 0.4517 - val_accuracy: 0.6816 - val_loss: 0.5852\n",
      "Epoch 5/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7837 - loss: 0.4457 - val_accuracy: 0.6831 - val_loss: 0.5913\n",
      "Epoch 6/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7835 - loss: 0.4468 - val_accuracy: 0.6720 - val_loss: 0.5985\n",
      "Epoch 7/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.7831 - loss: 0.4513 - val_accuracy: 0.6764 - val_loss: 0.6039\n",
      "Epoch 8/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7795 - loss: 0.4502 - val_accuracy: 0.6448 - val_loss: 0.6016\n",
      "Epoch 9/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7826 - loss: 0.4481 - val_accuracy: 0.6881 - val_loss: 0.5941\n",
      "Epoch 10/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7848 - loss: 0.4420 - val_accuracy: 0.6871 - val_loss: 0.5812\n",
      "Epoch 11/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7833 - loss: 0.4450 - val_accuracy: 0.6551 - val_loss: 0.6036\n",
      "Epoch 12/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7825 - loss: 0.4453 - val_accuracy: 0.7264 - val_loss: 0.5533\n",
      "Epoch 13/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7805 - loss: 0.4448 - val_accuracy: 0.7032 - val_loss: 0.5378\n",
      "Epoch 14/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7888 - loss: 0.4365 - val_accuracy: 0.6884 - val_loss: 0.5411\n",
      "Epoch 15/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7876 - loss: 0.4366 - val_accuracy: 0.6414 - val_loss: 0.5738\n",
      "Epoch 16/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7827 - loss: 0.4442 - val_accuracy: 0.6629 - val_loss: 0.6140\n",
      "Epoch 17/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7844 - loss: 0.4410 - val_accuracy: 0.6868 - val_loss: 0.5618\n",
      "Epoch 18/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7869 - loss: 0.4391 - val_accuracy: 0.6711 - val_loss: 0.5947\n",
      "Epoch 19/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7881 - loss: 0.4358 - val_accuracy: 0.6685 - val_loss: 0.5849\n",
      "Epoch 20/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7923 - loss: 0.4321 - val_accuracy: 0.6776 - val_loss: 0.5866\n",
      "Epoch 21/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7871 - loss: 0.4369 - val_accuracy: 0.6821 - val_loss: 0.5655\n",
      "Epoch 22/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7899 - loss: 0.4292 - val_accuracy: 0.6603 - val_loss: 0.5422\n",
      "Epoch 23/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7868 - loss: 0.4339 - val_accuracy: 0.7050 - val_loss: 0.5197\n",
      "Epoch 24/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7879 - loss: 0.4407 - val_accuracy: 0.6873 - val_loss: 0.5416\n",
      "Epoch 25/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7855 - loss: 0.4374 - val_accuracy: 0.6464 - val_loss: 0.5775\n",
      "Epoch 26/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7863 - loss: 0.4336 - val_accuracy: 0.6293 - val_loss: 0.5833\n",
      "Epoch 27/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7877 - loss: 0.4351 - val_accuracy: 0.7089 - val_loss: 0.5366\n",
      "Epoch 28/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7876 - loss: 0.4339 - val_accuracy: 0.6878 - val_loss: 0.5358\n",
      "Epoch 29/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7893 - loss: 0.4328 - val_accuracy: 0.6776 - val_loss: 0.5579\n",
      "Epoch 30/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7879 - loss: 0.4354 - val_accuracy: 0.7021 - val_loss: 0.5193\n",
      "Epoch 31/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7909 - loss: 0.4275 - val_accuracy: 0.6998 - val_loss: 0.5147\n",
      "Epoch 32/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7868 - loss: 0.4369 - val_accuracy: 0.6533 - val_loss: 0.5793\n",
      "Epoch 33/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7882 - loss: 0.4341 - val_accuracy: 0.6737 - val_loss: 0.5486\n",
      "Epoch 34/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.7896 - loss: 0.4316 - val_accuracy: 0.6848 - val_loss: 0.5417\n",
      "Epoch 35/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7847 - loss: 0.4345 - val_accuracy: 0.6589 - val_loss: 0.5852\n",
      "Epoch 36/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7882 - loss: 0.4314 - val_accuracy: 0.6877 - val_loss: 0.5699\n",
      "Epoch 37/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7942 - loss: 0.4319 - val_accuracy: 0.6694 - val_loss: 0.5711\n",
      "Epoch 38/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7946 - loss: 0.4300 - val_accuracy: 0.6658 - val_loss: 0.5817\n",
      "Epoch 39/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7887 - loss: 0.4305 - val_accuracy: 0.6569 - val_loss: 0.5546\n",
      "Epoch 40/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7893 - loss: 0.4346 - val_accuracy: 0.6211 - val_loss: 0.6005\n",
      "Epoch 41/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7888 - loss: 0.4308 - val_accuracy: 0.6499 - val_loss: 0.5596\n",
      "Epoch 42/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7883 - loss: 0.4341 - val_accuracy: 0.6289 - val_loss: 0.6092\n",
      "Epoch 43/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7906 - loss: 0.4316 - val_accuracy: 0.6633 - val_loss: 0.5900\n",
      "Epoch 44/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7900 - loss: 0.4298 - val_accuracy: 0.6708 - val_loss: 0.5625\n",
      "Epoch 45/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7880 - loss: 0.4314 - val_accuracy: 0.6630 - val_loss: 0.5674\n",
      "Epoch 46/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7900 - loss: 0.4312 - val_accuracy: 0.6868 - val_loss: 0.5504\n",
      "Epoch 47/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7881 - loss: 0.4329 - val_accuracy: 0.6380 - val_loss: 0.6211\n",
      "Epoch 48/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7889 - loss: 0.4323 - val_accuracy: 0.7102 - val_loss: 0.5205\n",
      "Epoch 49/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7891 - loss: 0.4338 - val_accuracy: 0.6472 - val_loss: 0.5733\n",
      "Epoch 50/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7859 - loss: 0.4373 - val_accuracy: 0.6471 - val_loss: 0.5883\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m512\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m17\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,413</span> (36.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m9,413\u001B[0m (36.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m3,137\u001B[0m (12.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,276</span> (24.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m6,276\u001B[0m (24.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.7426 - loss: 0.5201 - val_accuracy: 0.6204 - val_loss: 0.6275\n",
      "Epoch 2/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7750 - loss: 0.4606 - val_accuracy: 0.6721 - val_loss: 0.6062\n",
      "Epoch 3/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7782 - loss: 0.4582 - val_accuracy: 0.6134 - val_loss: 0.6512\n",
      "Epoch 4/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7799 - loss: 0.4518 - val_accuracy: 0.6946 - val_loss: 0.5980\n",
      "Epoch 5/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7787 - loss: 0.4506 - val_accuracy: 0.6502 - val_loss: 0.6347\n",
      "Epoch 6/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7794 - loss: 0.4504 - val_accuracy: 0.7204 - val_loss: 0.5678\n",
      "Epoch 7/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7860 - loss: 0.4448 - val_accuracy: 0.7132 - val_loss: 0.5409\n",
      "Epoch 8/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7836 - loss: 0.4419 - val_accuracy: 0.6920 - val_loss: 0.5709\n",
      "Epoch 9/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7797 - loss: 0.4478 - val_accuracy: 0.6838 - val_loss: 0.5832\n",
      "Epoch 10/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7801 - loss: 0.4468 - val_accuracy: 0.7077 - val_loss: 0.6056\n",
      "Epoch 11/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7806 - loss: 0.4472 - val_accuracy: 0.6758 - val_loss: 0.5978\n",
      "Epoch 12/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7788 - loss: 0.4420 - val_accuracy: 0.7006 - val_loss: 0.5660\n",
      "Epoch 13/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7788 - loss: 0.4475 - val_accuracy: 0.7008 - val_loss: 0.6050\n",
      "Epoch 14/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7737 - loss: 0.4559 - val_accuracy: 0.6582 - val_loss: 0.6118\n",
      "Epoch 15/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7835 - loss: 0.4454 - val_accuracy: 0.6651 - val_loss: 0.6365\n",
      "Epoch 16/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 5ms/step - accuracy: 0.7859 - loss: 0.4393 - val_accuracy: 0.6906 - val_loss: 0.5810\n",
      "Epoch 17/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7865 - loss: 0.4444 - val_accuracy: 0.7066 - val_loss: 0.5806\n",
      "Epoch 18/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7815 - loss: 0.4448 - val_accuracy: 0.6694 - val_loss: 0.5919\n",
      "Epoch 19/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7865 - loss: 0.4399 - val_accuracy: 0.7015 - val_loss: 0.5771\n",
      "Epoch 20/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7876 - loss: 0.4346 - val_accuracy: 0.7272 - val_loss: 0.5429\n",
      "Epoch 21/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7809 - loss: 0.4414 - val_accuracy: 0.6780 - val_loss: 0.5719\n",
      "Epoch 22/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7811 - loss: 0.4425 - val_accuracy: 0.6802 - val_loss: 0.6005\n",
      "Epoch 23/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7889 - loss: 0.4361 - val_accuracy: 0.7089 - val_loss: 0.6027\n",
      "Epoch 24/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7847 - loss: 0.4442 - val_accuracy: 0.6368 - val_loss: 0.6514\n",
      "Epoch 25/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7867 - loss: 0.4390 - val_accuracy: 0.6927 - val_loss: 0.5888\n",
      "Epoch 26/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7846 - loss: 0.4417 - val_accuracy: 0.6857 - val_loss: 0.6019\n",
      "Epoch 27/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7834 - loss: 0.4423 - val_accuracy: 0.7089 - val_loss: 0.5920\n",
      "Epoch 28/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7811 - loss: 0.4410 - val_accuracy: 0.7066 - val_loss: 0.5759\n",
      "Epoch 29/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7835 - loss: 0.4403 - val_accuracy: 0.7044 - val_loss: 0.5915\n",
      "Epoch 30/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7825 - loss: 0.4410 - val_accuracy: 0.6910 - val_loss: 0.6193\n",
      "Epoch 31/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7876 - loss: 0.4353 - val_accuracy: 0.7099 - val_loss: 0.5805\n",
      "Epoch 32/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7829 - loss: 0.4371 - val_accuracy: 0.6921 - val_loss: 0.6098\n",
      "Epoch 33/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7912 - loss: 0.4313 - val_accuracy: 0.7003 - val_loss: 0.6185\n",
      "Epoch 34/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7906 - loss: 0.4304 - val_accuracy: 0.6991 - val_loss: 0.5935\n",
      "Epoch 35/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7852 - loss: 0.4380 - val_accuracy: 0.6738 - val_loss: 0.6394\n",
      "Epoch 36/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7891 - loss: 0.4354 - val_accuracy: 0.6762 - val_loss: 0.6126\n",
      "Epoch 37/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7857 - loss: 0.4358 - val_accuracy: 0.7068 - val_loss: 0.5957\n",
      "Epoch 38/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7902 - loss: 0.4324 - val_accuracy: 0.7252 - val_loss: 0.5829\n",
      "Epoch 39/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7842 - loss: 0.4360 - val_accuracy: 0.6953 - val_loss: 0.5863\n",
      "Epoch 40/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7865 - loss: 0.4378 - val_accuracy: 0.6723 - val_loss: 0.6137\n",
      "Epoch 41/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7881 - loss: 0.4385 - val_accuracy: 0.7256 - val_loss: 0.5605\n",
      "Epoch 42/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7882 - loss: 0.4356 - val_accuracy: 0.6915 - val_loss: 0.6181\n",
      "Epoch 43/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.7841 - loss: 0.4341 - val_accuracy: 0.6903 - val_loss: 0.6077\n",
      "Epoch 44/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7901 - loss: 0.4314 - val_accuracy: 0.7168 - val_loss: 0.5813\n",
      "Epoch 45/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7873 - loss: 0.4334 - val_accuracy: 0.7131 - val_loss: 0.6009\n",
      "Epoch 46/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7862 - loss: 0.4353 - val_accuracy: 0.7001 - val_loss: 0.5932\n",
      "Epoch 47/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7906 - loss: 0.4343 - val_accuracy: 0.7007 - val_loss: 0.6243\n",
      "Epoch 48/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7884 - loss: 0.4324 - val_accuracy: 0.7111 - val_loss: 0.5714\n",
      "Epoch 49/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.7854 - loss: 0.4395 - val_accuracy: 0.6799 - val_loss: 0.6146\n",
      "Epoch 50/50\n",
      "\u001B[1m989/989\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7837 - loss: 0.4378 - val_accuracy: 0.7171 - val_loss: 0.5415\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m512\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m17\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,413</span> (36.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m9,413\u001B[0m (36.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m3,137\u001B[0m (12.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,276</span> (24.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m6,276\u001B[0m (24.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#your code here:\n",
    "# 1) First Method\n",
    "\n",
    "# Define the model architecture\n",
    "model_first = Sequential()\n",
    "model_first.add(Dense(64, input_dim=X_train_first_balanced_classification.shape[1], activation='relu'))\n",
    "model_first.add(Dense(32, activation='relu'))\n",
    "model_first.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "model_first.add(Dense(16, activation='relu'))\n",
    "model_first.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_first.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_first = model_first.fit(X_train_first_balanced_classification, y_train_first_encoded_classification, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Summary of the model\n",
    "model_first.summary()\n",
    "\n",
    "# 2) Second Method\n",
    "# Define the model architecture\n",
    "model_second = Sequential()\n",
    "model_second.add(Dense(64, input_dim=X_train_second_balanced_classification.shape[1], activation='relu'))\n",
    "model_second.add(Dense(32, activation='relu'))\n",
    "model_second.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "model_second.add(Dense(16, activation='relu'))\n",
    "model_second.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_second.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_second = model_second.fit(X_train_second_balanced_classification, y_train_second_encoded_classification, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Summary of the model\n",
    "model_second.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrdwJiEdkzP4"
   },
   "source": [
    "#Explain the structure of the network: how many layers? what layers? how manny weights/coefficients/parameters are there in your network? (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKUQFV4blHX1"
   },
   "source": [
    "#Your answer here: <br>\n",
    "Both neural network consists of 4 layers: three hidden layers and one output layer. The first hidden layer has 64 neurons, the second 32 and the last one 16 neurons, using ReLU activation functions. We also used A dropout layer with a rate of 0.5 for preventing overfitting. The output layer has 1 neuron with a sigmoid activation function for binary classification. In total, the network has 9,413 parameters where 3,137 are trainable, and 6,276 are related to the optimizer parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXR9AHo9Y3gJ"
   },
   "source": [
    "#9. a. Predict the y variable on both the train set and the test set (for both imputed datasets and for both algorithms - 16 predictions in total):\n",
    "2 imputed datasets * 4 models * (train+test)\n",
    "\n",
    "and print the accuracy of each prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OGXWpYFLZyHh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mRandom Forest:\u001B[0m\n",
      "Accuracy for Random Forest on First Imputed Dataset - Train Set: 0.9981292345029831\n",
      "Accuracy for Random Forest on First Imputed Dataset - Test Set: 0.7931828650391525\n",
      "\n",
      "\u001B[1mXGBoost:\u001B[0m\n",
      "Accuracy for XGBoost on First Imputed Dataset - Train Set: 0.897689351805036\n",
      "Accuracy for XGBoost on First Imputed Dataset - Test Set: 0.8192845079072624\n",
      "\n",
      "\u001B[1mHistGradientBoosting:\u001B[0m\n",
      "Accuracy for HistGradientBoosting on First Imputed Dataset - Train Set: 0.8640914147032056\n",
      "Accuracy for HistGradientBoosting on First Imputed Dataset - Test Set: 0.8037770612620913\n",
      "\n",
      "\u001B[1m1237/1237\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step\n",
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "\u001B[1mNeural Network:\u001B[0m\n",
      "Accuracy for Neural Network on First Imputed Dataset - Train Set: 0.7643088279906968\n",
      "Accuracy for Neural Network on First Imputed Dataset - Test Set: 0.8165208045447566\n",
      "\n",
      "\u001B[1mRandom Forest:\u001B[0m\n",
      "Accuracy for Random Forest on Second Imputed Dataset - Train Set: 0.9980281120436849\n",
      "Accuracy for Random Forest on Second Imputed Dataset - Test Set: 0.7898050053738677\n",
      "\n",
      "\u001B[1mXGBoost:\u001B[0m\n",
      "Accuracy for XGBoost on Second Imputed Dataset - Train Set: 0.8978157548791587\n",
      "Accuracy for XGBoost on Second Imputed Dataset - Test Set: 0.8165208045447566\n",
      "\n",
      "\u001B[1mHistGradientBoosting:\u001B[0m\n",
      "Accuracy for HistGradientBoosting on Second Imputed Dataset - Train Set: 0.8674537364748711\n",
      "Accuracy for HistGradientBoosting on Second Imputed Dataset - Test Set: 0.8037770612620913\n",
      "\n",
      "\u001B[1m1237/1237\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step\n",
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "\u001B[1mNeural Network:\u001B[0m\n",
      "Accuracy for Neural Network on Second Imputed Dataset - Train Set: 0.7753817372838507\n",
      "Accuracy for Neural Network on Second Imputed Dataset - Test Set: 0.7970213419315215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": [rf_grid_first, rf_grid_second],\n",
    "    \"XGBoost\": [xgb_grid_first, xgb_grid_second],\n",
    "    \"HistGradientBoosting\": [hgb_grid_first, hgb_grid_second],\n",
    "    \"Neural Network\": [model_first, model_second]  # Assuming Keras models for both datasets\n",
    "}\n",
    "\n",
    "imputed_datasets = [\"First Imputed Dataset\", \"Second Imputed Dataset\"]\n",
    "label_encoders = [label_encoder_first, label_encoder_second]\n",
    "X_train_sets_classification = [X_train_first_balanced_classification, X_train_second_balanced_classification]\n",
    "X_test_sets_classification = [X_test_first_scaled_classification, X_test_second_scaled_classification]\n",
    "y_train_sets_classification = [y_train_first_encoded_classification, y_train_second_encoded_classification]\n",
    "y_test_sets_classification = [y_test_first_encoded_classification, y_test_second_encoded_classification]\n",
    "\n",
    "\n",
    "def evaluate_models(models, imputed_datasets, label_encoders, X_train_sets, X_test_sets, y_train_sets, y_test_sets):\n",
    "    # Predicting on both train and test for each model and imputed dataset\n",
    "    for dataset_idx, dataset_name in enumerate(imputed_datasets):\n",
    "        label_encoder = label_encoders[dataset_idx]\n",
    "        X_train_classification = X_train_sets[dataset_idx]\n",
    "        X_test_classification = X_test_sets[dataset_idx]\n",
    "        y_train_classification = y_train_sets[dataset_idx]\n",
    "        y_test_classification = y_test_sets[dataset_idx]\n",
    "\n",
    "        for model_name, model_variants in models.items():\n",
    "            model = model_variants[dataset_idx]\n",
    "            \n",
    "            if model_name == \"Neural Network\":\n",
    "                # Neural network models have different predict method\n",
    "                y_train_pred_classification = (model.predict(X_train_classification) > 0.5).astype(\"int32\")\n",
    "                y_test_pred_classification = (model.predict(X_test_classification) > 0.5).astype(\"int32\")\n",
    "            else:\n",
    "                y_train_pred_classification = model.predict(X_train_classification)\n",
    "                y_test_pred_classification = model.predict(X_test_classification)\n",
    "\n",
    "            # Only apply inverse transformation to predictions\n",
    "            y_train_pred_classification = label_encoder.inverse_transform(y_train_pred_classification)\n",
    "            y_test_pred_classification = label_encoder.inverse_transform(y_test_pred_classification)\n",
    "\n",
    "            # Print accuracy with bold model name\n",
    "            print(f\"\\033[1m{model_name}:\\033[0m\")\n",
    "            print(f\"Accuracy for {model_name} on {dataset_name} - Train Set: {accuracy_score(label_encoder.inverse_transform(y_train_classification), y_train_pred_classification)}\")\n",
    "            print(f\"Accuracy for {model_name} on {dataset_name} - Test Set: {accuracy_score(label_encoder.inverse_transform(y_test_classification), y_test_pred_classification)}\")\n",
    "            print()\n",
    "\n",
    "evaluate_models(models, imputed_datasets, label_encoders, X_train_sets_classification, X_test_sets_classification, y_train_sets_classification, y_test_sets_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0q70fd0FZzqS"
   },
   "source": [
    "#b. Based on the accuracies of the predictions, verbally explain which model resulted with the best outcome with consideration to over-fitting, under-fitting and proper-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8EIHUuGa5Cu"
   },
   "source": [
    "#Your answer here:\n",
    "Based on the accuracies, XGBoost provided the best outcome, and show good performance between on both training set (> 89%) and test set (>81%), which indicate proper-fitting and generalization. Random Forest showed  overfitting with very high training accuracy on both sets (>99%) compared to test accuracy (>78%). HistGradientBoosting also showed balanced fitting but with a bit less effective accuracies than XGBoost. The Neural Network showed potential underfitting with a lower training accuracy on both sets (>76%) compared to test accuracy (>79%), suggesting that it may benefit from more training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjsR7CqOaRnC"
   },
   "source": [
    "#Print the classification_report of the test set using the best model and verbally explain another quality measure of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lqPM-0PVa1Ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores for All Models:\n",
      "\n",
      "Random Forest - First Imputed Dataset\n",
      "F1 Score on Train Set: 0.9981292342686409\n",
      "F1 Score on Test Set: 0.794084125843399\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Random Forest - Second Imputed Dataset\n",
      "F1 Score on Train Set: 0.9980281117210603\n",
      "F1 Score on Test Set: 0.7916616472075105\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "XGBoost - First Imputed Dataset\n",
      "F1 Score on Train Set: 0.897652459775552\n",
      "F1 Score on Test Set: 0.8201470834086527\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "XGBoost - Second Imputed Dataset\n",
      "F1 Score on Train Set: 0.8977820764981156\n",
      "F1 Score on Test Set: 0.8187857366885654\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "HistGradientBoosting - First Imputed Dataset\n",
      "F1 Score on Train Set: 0.8640877285924949\n",
      "F1 Score on Test Set: 0.8086570282605945\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "HistGradientBoosting - Second Imputed Dataset\n",
      "F1 Score on Train Set: 0.8674505809783183\n",
      "F1 Score on Test Set: 0.8087854976912914\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Neural Network - First Imputed Dataset\n",
      "\u001B[1m1237/1237\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "F1 Score on Train Set: 0.7612338125622312\n",
      "F1 Score on Test Set: 0.8180683678938624\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Neural Network - Second Imputed Dataset\n",
      "\u001B[1m1237/1237\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step\n",
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n",
      "F1 Score on Train Set: 0.7746739249900468\n",
      "F1 Score on Test Set: 0.8043439586628541\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Classification Report for Best Models (XGBoost):\n",
      "\n",
      "Classification Report for First Imputed Dataset:\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.88      0.88      0.88      4942\n",
      "        >50K       0.62      0.64      0.63      1571\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.75      0.76      0.76      6513\n",
      "weighted avg       0.82      0.82      0.82      6513\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Classification Report for Second Imputed Dataset:\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.87      0.88      4942\n",
      "        >50K       0.61      0.66      0.63      1571\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.75      0.76      0.76      6513\n",
      "weighted avg       0.82      0.82      0.82      6513\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to print F1 scores for train and test sets for any model\n",
    "def print_f1_scores(model, X_train, y_train, X_test, y_test, label_encoder, is_neural_network=False):\n",
    "    # Predict for train and test sets\n",
    "    if is_neural_network:\n",
    "        y_train_pred = (model.predict(X_train) > 0.5).astype(\"int32\")\n",
    "        y_test_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Reverse label encoding for interpretation\n",
    "    y_train = label_encoder.inverse_transform(y_train)\n",
    "    y_test = label_encoder.inverse_transform(y_test)\n",
    "    y_train_pred = label_encoder.inverse_transform(y_train_pred)\n",
    "    y_test_pred = label_encoder.inverse_transform(y_test_pred)\n",
    "\n",
    "    # Calculate F1 scores\n",
    "    f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    print(f\"F1 Score on Train Set: {f1_train}\")\n",
    "    print(f\"F1 Score on Test Set: {f1_test}\")\n",
    "\n",
    "# Function to print classification report for the best models only\n",
    "def print_classification_report(model, X_test, y_test, label_encoder, is_neural_network=False):\n",
    "    # Predict for train and test sets\n",
    "    if is_neural_network:\n",
    "        y_test_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Reverse label encoding for interpretation\n",
    "    y_test = label_encoder.inverse_transform(y_test)\n",
    "    y_test_pred = label_encoder.inverse_transform(y_test_pred)\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report on Test Set:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "# Models and label encoders\n",
    "models = {\n",
    "    \"Random Forest\": [rf_grid_first, rf_grid_second],\n",
    "    \"XGBoost\": [xgb_grid_first, xgb_grid_second],\n",
    "    \"HistGradientBoosting\": [hgb_grid_first, hgb_grid_second],\n",
    "    \"Neural Network\": [model_first, model_second]  # Assuming Keras models for both datasets\n",
    "}\n",
    "\n",
    "# Print F1 scores for each model\n",
    "print(\"F1 Scores for All Models:\\n\")\n",
    "for model_name, model_variants in models.items():\n",
    "    for dataset_idx, model in enumerate(model_variants):\n",
    "        print(f\"{model_name} - {'First' if dataset_idx == 0 else 'Second'} Imputed Dataset\")\n",
    "        label_encoder = label_encoders[dataset_idx]\n",
    "        X_train = X_train_sets_classification[dataset_idx]\n",
    "        X_test = X_test_sets_classification[dataset_idx]\n",
    "        y_train = y_train_sets_classification[dataset_idx]\n",
    "        y_test = y_test_sets_classification[dataset_idx]\n",
    "\n",
    "        is_neural_network = model_name == \"Neural Network\"\n",
    "        print_f1_scores(model, X_train, y_train, X_test, y_test, label_encoder, is_neural_network)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Print classification report for the best models only\n",
    "best_models = [xgb_grid_first, xgb_grid_second]\n",
    "print(\"Classification Report for Best Models (XGBoost):\\n\")\n",
    "for i, model in enumerate(best_models):\n",
    "    label_encoder = label_encoders[i]\n",
    "    X_test = X_test_sets_classification[i]\n",
    "    y_test = y_test_sets_classification[i]\n",
    "    \n",
    "    print(f\"Classification Report for {'First' if i == 0 else 'Second'} Imputed Dataset:\")\n",
    "    print_classification_report(model, X_test, y_test, label_encoder)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyUVqCG6a5mq"
   },
   "source": [
    "#Your answer here: <br>\n",
    "Based on the F1 score, the XGBoost model still demonstrated the best performance on both the training and test sets. The F1 score is a good metric and relevant to the world of the content of our prediction question because it balances precision and recall and effectively evaluates model performance in cases of class imbalance. Since we used SMOTE to create synthetic examples for the minority class, the F1 score provides a better indication of how well our model learned to handle the minority class after balancing and therefore this metric is more reliable than accuracy for our prediction task, where identifying both classes accurately is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjlVS3N9mITn"
   },
   "source": [
    "#Part B:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkXSaeKKmK-D"
   },
   "source": [
    "#10. Data preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTJaRDNTmXu6"
   },
   "source": [
    "#Upload the second table (for regression analysis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wxnogzcqmVBY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSTED_BY</th>\n",
       "      <th>UNDER_CONSTRUCTION</th>\n",
       "      <th>RERA</th>\n",
       "      <th>BHK_NO.</th>\n",
       "      <th>BHK_OR_RK</th>\n",
       "      <th>SQUARE_FT</th>\n",
       "      <th>READY_TO_MOVE</th>\n",
       "      <th>RESALE</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>TARGET(PRICE_IN_LACS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21992</th>\n",
       "      <td>Dealer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>BHK</td>\n",
       "      <td>1057.896332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nayabad,Kolkata</td>\n",
       "      <td>22.483471</td>\n",
       "      <td>88.417711</td>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>Dealer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>BHK</td>\n",
       "      <td>1340.588282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sector 42 Seawoods,Lalitpur</td>\n",
       "      <td>28.456809</td>\n",
       "      <td>77.099182</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>Dealer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BHK</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Indirapuram,Ghaziabad</td>\n",
       "      <td>28.636760</td>\n",
       "      <td>77.363150</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>Owner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>BHK</td>\n",
       "      <td>1800.327332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Navratna Complex,Udaipur</td>\n",
       "      <td>24.583330</td>\n",
       "      <td>73.683330</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28825</th>\n",
       "      <td>Dealer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BHK</td>\n",
       "      <td>903.024911</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Madhyamgram,Kolkata</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>88.450000</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      POSTED_BY  UNDER_CONSTRUCTION  RERA  BHK_NO. BHK_OR_RK    SQUARE_FT  \\\n",
       "21992    Dealer                   0     0        3       BHK  1057.896332   \n",
       "29060    Dealer                   0     0        3       BHK  1340.588282   \n",
       "6778     Dealer                   0     0        2       BHK   800.000000   \n",
       "4730      Owner                   0     0        3       BHK  1800.327332   \n",
       "28825    Dealer                   1     0        2       BHK   903.024911   \n",
       "\n",
       "       READY_TO_MOVE  RESALE                      ADDRESS  LONGITUDE  \\\n",
       "21992              1       1              Nayabad,Kolkata  22.483471   \n",
       "29060              1       1  Sector 42 Seawoods,Lalitpur  28.456809   \n",
       "6778               1       1        Indirapuram,Ghaziabad  28.636760   \n",
       "4730               1       1     Navratna Complex,Udaipur  24.583330   \n",
       "28825              0       1          Madhyamgram,Kolkata  22.700000   \n",
       "\n",
       "        LATITUDE  TARGET(PRICE_IN_LACS)  \n",
       "21992  88.417711                   34.9  \n",
       "29060  77.099182                  170.0  \n",
       "6778   77.363150                   35.0  \n",
       "4730   73.683330                   55.0  \n",
       "28825  88.450000                   20.3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here:\n",
    "# Link to the dataset: https://www.kaggle.com/datasets/anmolkumar/house-price-prediction-challenge?select=train.csv\n",
    "# Load the full dataset\n",
    "regression_df = pd.read_csv(\"data_for_regression/train.csv\")\n",
    "\n",
    "# We will Randomly sample 5000 rows with a fixed random_state because the dataset is too large\n",
    "regression_df = regression_df.sample(n=1500, random_state=42)\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6cVe6RjmVBZ"
   },
   "source": [
    "#Read the file into a pandas data frame:\n",
    "Split your data to:\n",
    "\n",
    "a. X: the feature matrix\n",
    "\n",
    "b. y: the label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_Yt0dPZJmVBa"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "X_regression = regression_df.drop(columns=['TARGET(PRICE_IN_LACS)'])\n",
    "y_regression = regression_df['TARGET(PRICE_IN_LACS)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5atIA5pm6Z_"
   },
   "source": [
    "#10.A. Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hd-y5pz7m6aB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null values: POSTED_BY                0\n",
      "UNDER_CONSTRUCTION       0\n",
      "RERA                     0\n",
      "BHK_NO.                  0\n",
      "BHK_OR_RK                0\n",
      "SQUARE_FT                0\n",
      "READY_TO_MOVE            0\n",
      "RESALE                   0\n",
      "ADDRESS                  0\n",
      "LONGITUDE                0\n",
      "LATITUDE                 0\n",
      "TARGET(PRICE_IN_LACS)    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "print(f'Number of Null values: {regression_df.isnull().sum()}')\n",
    "\n",
    "# I also checked for duplicates values and found 14 duplicates\n",
    "print(f'Number of Duplicated values: {regression_df.duplicated().sum()}')\n",
    "\n",
    "# Drop duplicates and keep only the first occurrence\n",
    "regression_df = regression_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXy2Hq7dm6aB"
   },
   "source": [
    "#10.B. Impute the missing values using two different methods and assign the imputed output datasets into variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "c-brL9oXm6aC"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "#None of the columns have missing values, so we can proceed with the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl6vefQem6aC"
   },
   "source": [
    "#10.C. Convert categorical features to dummy variables if number of categories is lower than 5, otherwise remove from data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BTrcdLfQm6aD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values in 'POSTED_BY': 3\n",
      "Column 'POSTED_BY' has 4 or fewer categories and can be converted to dummy variables.\n",
      "Distinct values in 'BHK_OR_RK': 2\n",
      "Column 'BHK_OR_RK' has 4 or fewer categories and can be converted to dummy variables.\n",
      "Distinct values in 'ADDRESS': 1021\n",
      "Column 'ADDRESS' has more than 4 categories and should be removed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNDER_CONSTRUCTION</th>\n",
       "      <th>RERA</th>\n",
       "      <th>BHK_NO.</th>\n",
       "      <th>SQUARE_FT</th>\n",
       "      <th>READY_TO_MOVE</th>\n",
       "      <th>RESALE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>POSTED_BY_Dealer</th>\n",
       "      <th>POSTED_BY_Owner</th>\n",
       "      <th>BHK_OR_RK_RK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1057.896332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.483471</td>\n",
       "      <td>88.417711</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1340.588282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.456809</td>\n",
       "      <td>77.099182</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.636760</td>\n",
       "      <td>77.363150</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1800.327332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.583330</td>\n",
       "      <td>73.683330</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28825</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>903.024911</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>88.450000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UNDER_CONSTRUCTION  RERA  BHK_NO.    SQUARE_FT  READY_TO_MOVE  RESALE  \\\n",
       "21992                   0     0        3  1057.896332              1       1   \n",
       "29060                   0     0        3  1340.588282              1       1   \n",
       "6778                    0     0        2   800.000000              1       1   \n",
       "4730                    0     0        3  1800.327332              1       1   \n",
       "28825                   1     0        2   903.024911              0       1   \n",
       "\n",
       "       LONGITUDE   LATITUDE  POSTED_BY_Dealer  POSTED_BY_Owner  BHK_OR_RK_RK  \n",
       "21992  22.483471  88.417711              True            False         False  \n",
       "29060  28.456809  77.099182              True            False         False  \n",
       "6778   28.636760  77.363150              True            False         False  \n",
       "4730   24.583330  73.683330             False             True         False  \n",
       "28825  22.700000  88.450000              True            False         False  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here:\n",
    "# Iterate through categorical columns and count distinct values\n",
    "numerical_cols_1 = X_regression.select_dtypes(include=['int64']).columns\n",
    "categorical_cols_1 = X_regression.select_dtypes(include=['object']).columns\n",
    "\n",
    "columns_to_remove_1 = []\n",
    "for col in categorical_cols_1:\n",
    "    unique_values = X_regression[col].nunique()\n",
    "    print(f\"Distinct values in '{col}': {unique_values}\")\n",
    "    \n",
    "    # Check if the column has more than 4 categories\n",
    "    if unique_values > 4:\n",
    "        print(f\"Column '{col}' has more than 4 categories and should be removed.\")\n",
    "        columns_to_remove_1.append(col)\n",
    "    else:\n",
    "        print(f\"Column '{col}' has 4 or fewer categories and can be converted to dummy variables.\")\n",
    "\n",
    "# Drop the columns with more than 4 categories\n",
    "X_cleaned_regression = X_regression.drop(columns=columns_to_remove_1)\n",
    "\n",
    "# Convert remaining categorical columns (with 4 or fewer categories) to dummy variables\n",
    "X_cleaned_regression = pd.get_dummies(X_cleaned_regression, drop_first=True)\n",
    "\n",
    "X_cleaned_regression.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNDER_CONSTRUCTION</th>\n",
       "      <th>RERA</th>\n",
       "      <th>BHK_NO.</th>\n",
       "      <th>SQUARE_FT</th>\n",
       "      <th>READY_TO_MOVE</th>\n",
       "      <th>RESALE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.299333</td>\n",
       "      <td>2.38000</td>\n",
       "      <td>2039.983887</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>21.285463</td>\n",
       "      <td>77.132794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.389236</td>\n",
       "      <td>0.458119</td>\n",
       "      <td>0.80666</td>\n",
       "      <td>11162.639675</td>\n",
       "      <td>0.389236</td>\n",
       "      <td>0.254105</td>\n",
       "      <td>6.092555</td>\n",
       "      <td>8.893045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.182037</td>\n",
       "      <td>-86.152929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>900.186468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.461698</td>\n",
       "      <td>73.804299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1182.401299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.534403</td>\n",
       "      <td>77.304492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1531.656049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.867658</td>\n",
       "      <td>77.774248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>230000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.556894</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UNDER_CONSTRUCTION         RERA     BHK_NO.      SQUARE_FT  \\\n",
       "count         1500.000000  1500.000000  1500.00000    1500.000000   \n",
       "mean             0.186000     0.299333     2.38000    2039.983887   \n",
       "std              0.389236     0.458119     0.80666   11162.639675   \n",
       "min              0.000000     0.000000     1.00000      32.000000   \n",
       "25%              0.000000     0.000000     2.00000     900.186468   \n",
       "50%              0.000000     0.000000     2.00000    1182.401299   \n",
       "75%              0.000000     1.000000     3.00000    1531.656049   \n",
       "max              1.000000     1.000000     8.00000  230000.000000   \n",
       "\n",
       "       READY_TO_MOVE       RESALE    LONGITUDE     LATITUDE  \n",
       "count    1500.000000  1500.000000  1500.000000  1500.000000  \n",
       "mean        0.814000     0.930667    21.285463    77.132794  \n",
       "std         0.389236     0.254105     6.092555     8.893045  \n",
       "min         0.000000     0.000000     9.182037   -86.152929  \n",
       "25%         1.000000     1.000000    18.461698    73.804299  \n",
       "50%         1.000000     1.000000    20.534403    77.304492  \n",
       "75%         1.000000     1.000000    26.867658    77.774248  \n",
       "max         1.000000     1.000000    52.556894   136.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned_regression.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItZzsxOGm6aD"
   },
   "source": [
    "#10.D. Train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size (first): (1200, 11), (1200,)\n",
      "Test set size (first): (300, 11), (300,)\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "\n",
    "# 1) First Imputed Dataset:\n",
    "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(\n",
    "    X_cleaned_regression, y_regression, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the sizes to confirm\n",
    "print(f\"Train set size (first): {X_train_regression.shape}, {y_train_regression.shape}\")\n",
    "print(f\"Test set size (first): {X_test_regression.shape}, {y_test_regression.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWbyIGVvm6aE"
   },
   "source": [
    "#10.E. standardize or normalize the data\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "RWrtiYf9m6aE"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "# Create a MinMaxScaler object\n",
    "scaler_first = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test sets\n",
    "X_train_normalized_regression = scaler_first.fit_transform(X_train_regression)\n",
    "X_test_normalized_regression = scaler_first.transform(X_test_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx4FjmJgnP92"
   },
   "source": [
    "#11. Train a linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Jmihk-OGoAJk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here:\n",
    "# Initialize the Linear Regression model\n",
    "linear_regression_model = LinearRegression()\n",
    "\n",
    "# Train the model on the normalized training set\n",
    "linear_regression_model.fit(X_train_normalized_regression, y_train_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfRk86hInXlI"
   },
   "source": [
    "#12. On both the train set and the test set, predict the values based on the linear regression model and print the following measures:\n",
    "\n",
    "\t*  R^2\n",
    "\t*  Root Mean Square Error (RMSE)\n",
    "\t*  Mean Absolut Error (MAE)\n",
    "\t*  Mean Absolut Percent Error (MAPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Z_ZELtEloBfl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Metrics:\n",
      "R^2: 0.06557754241865377\n",
      "Root Mean Square Error (RMSE): 392.33133497083816\n",
      "Mean Absolute Error (MAE): 202.45583333333332\n",
      "Mean Absolute Percentage Error (MAPE): 364.68299641192425\n",
      "\n",
      "Test Set Metrics:\n",
      "R^2: 0.3713581211604169\n",
      "Root Mean Square Error (RMSE): 633.8240863467823\n",
      "Mean Absolute Error (MAE): 231.02700000000002\n",
      "Mean Absolute Percentage Error (MAPE): 314.4221436509358\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "# Function to calculate Mean Absolute Percentage Error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred_regression = linear_regression_model.predict(X_train_normalized_regression)\n",
    "y_test_pred_regression = linear_regression_model.predict(X_test_normalized_regression)\n",
    "\n",
    "# Calculate metrics for the train set\n",
    "print(\"Train Set Metrics:\")\n",
    "r2_train = r2_score(y_train_regression, y_train_pred_regression)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_regression, y_train_pred_regression))\n",
    "mae_train = mean_absolute_error(y_train_regression, y_train_pred_regression)\n",
    "mape_train = mean_absolute_percentage_error(y_train_regression, y_train_pred_regression)\n",
    "\n",
    "print(f\"R^2: {r2_train}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse_train}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_train}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape_train}\")\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "r2_test = r2_score(y_test_regression, y_test_pred_regression)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_regression, y_test_pred_regression))\n",
    "mae_test = mean_absolute_error(y_test_regression, y_test_pred_regression)\n",
    "mape_test = mean_absolute_percentage_error(y_test_regression, y_test_pred_regression)\n",
    "\n",
    "print(f\"R^2: {r2_test}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse_test}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these metrics shows that the model is not learning well the relationship between the features and the target. The low R² values and high errors (RMSE, MAE, MAPE) suggest us that the linear regression model can be not be not a good for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmoF2nk9oFT-"
   },
   "source": [
    "#13. Polynomial regression: follow instruction in the attached documnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "KGQ-10jLoR_l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree: 2\n",
      "Lasso Regression\n",
      "Ridge Regression\n",
      "\n",
      "Degree: 3\n",
      "Lasso Regression\n",
      "Ridge Regression\n",
      "\n",
      "Degree: 4\n",
      "Lasso Regression\n",
      "Ridge Regression\n",
      "Best Degree: 2\n",
      "Best Model: Lasso\n",
      "Best Alpha: 100\n",
      "\n",
      "Train Set Metrics:\n",
      "R^2: 0.9305547742140763\n",
      "Root Mean Square Error (RMSE): 106.95536136031029\n",
      "Mean Absolute Error (MAE): 52.385538639276845\n",
      "Mean Absolute Percentage Error (MAPE): 68.46889573038459\n",
      "\n",
      "Test Set Metrics:\n",
      "R^2: 0.8083572559718445\n",
      "Root Mean Square Error (RMSE): 349.95586363147584\n",
      "Mean Absolute Error (MAE): 76.74764989496427\n",
      "Mean Absolute Percentage Error (MAPE): 64.93001723099695\n"
     ]
    }
   ],
   "source": [
    "#your code here:\n",
    "# Define polynomial degrees to try\n",
    "degrees = [2, 3, 4]\n",
    "best_model = None\n",
    "best_degree = None\n",
    "best_alpha = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "# Loop through each degree\n",
    "for d in degrees:\n",
    "    print(f\"\\nDegree: {d}\")\n",
    "    # Generate polynomial features\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    X_poly = poly.fit_transform(X_cleaned_regression)\n",
    "    \n",
    "    # Split the data with the same random state\n",
    "    X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(\n",
    "        X_poly, y_regression, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define the parameter grid for alpha\n",
    "    param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "    \n",
    "    # Lasso Regression with GridSearchCV\n",
    "    print(\"Lasso Regression\")\n",
    "    lasso = Lasso(max_iter=10000)\n",
    "    lasso_grid = GridSearchCV(lasso, param_grid, cv=3, scoring='r2')\n",
    "    lasso_grid.fit(X_train_poly, y_train_poly)\n",
    "    \n",
    "    # Ridge Regression with GridSearchCV\n",
    "    print(\"Ridge Regression\")\n",
    "    ridge = Ridge(max_iter=10000)\n",
    "    ridge_grid = GridSearchCV(ridge, param_grid, cv=3, scoring='r2')\n",
    "    ridge_grid.fit(X_train_poly, y_train_poly)\n",
    "    \n",
    "    # Determine best model and parameters for current degree\n",
    "    best_lasso_score = lasso_grid.best_score_\n",
    "    best_ridge_score = ridge_grid.best_score_\n",
    "    \n",
    "    if best_lasso_score > best_score:\n",
    "        best_score = best_lasso_score\n",
    "        best_model = lasso_grid.best_estimator_\n",
    "        best_degree = d\n",
    "        best_alpha = lasso_grid.best_params_['alpha']\n",
    "    \n",
    "    if best_ridge_score > best_score:\n",
    "        best_score = best_ridge_score\n",
    "        best_model = ridge_grid.best_estimator_\n",
    "        best_degree = d\n",
    "        best_alpha = ridge_grid.best_params_['alpha']\n",
    "\n",
    "# Display the best model details\n",
    "print(f\"Best Degree: {best_degree}\")\n",
    "print(f\"Best Model: {'Lasso' if isinstance(best_model, Lasso) else 'Ridge'}\")\n",
    "print(f\"Best Alpha: {best_alpha}\")\n",
    "\n",
    "\n",
    "# Initialize PolynomialFeatures with the best degree found (e.g., degree=d)\n",
    "poly = PolynomialFeatures(degree=best_degree)\n",
    "\n",
    "# Transform the entire dataset, then split\n",
    "X_poly = poly.fit_transform(X_cleaned_regression)\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(\n",
    "    X_poly, y_regression, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you can train and test using the transformed sets with consistent feature numbers\n",
    "y_train_pred = best_model.predict(X_train_poly)\n",
    "y_test_pred = best_model.predict(X_test_poly)\n",
    "\n",
    "# Calculate and display metrics for train set\n",
    "print(\"\\nTrain Set Metrics:\")\n",
    "print(f\"R^2: {r2_score(y_train_poly, y_train_pred)}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {np.sqrt(mean_squared_error(y_train_poly, y_train_pred))}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_train_poly, y_train_pred)}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mean_absolute_percentage_error(y_train_poly, y_train_pred)}\")\n",
    "\n",
    "# Calculate and display metrics for test set\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"R^2: {r2_score(y_test_poly, y_test_pred)}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {np.sqrt(mean_squared_error(y_test_poly, y_test_pred))}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test_poly, y_test_pred)}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mean_absolute_percentage_error(y_test_poly, y_test_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvIm0OEUoUSW"
   },
   "source": [
    "#14. Verbally explain the problem with polynomial transformation of features. How can it be solved? (2-3 sentences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivECb4FOo9jY"
   },
   "source": [
    "#Your answer here: <br>\n",
    "The problem with polynomial transformation of features is that it can lead to multicollinearity (features are highly correlated with each other) and very large feature values (because we square, cube,.. the orginal values), which can lead to instability in the model and make convergence more difficult. To solve this problem we can use regularization techniques like Lasso and Ridge to reduce model the complexity and improve the stability of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsvLKBFHoqe1"
   },
   "source": [
    "#Verbally explain what are ridge and lasso? when shoud each be used? what's the diffrence between them? (up to 4 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Aj-zGZNo9_A"
   },
   "source": [
    "#Your answer here: <br>\n",
    "Lasso and Ridge are two differents regularization techniques that we use in order to prevent overfitting. Lasso (L1 regularization) is a good choice when we want to simplify the model by setting some feature coefficients to zero, which automatically selects the most important features. Ridge (L2 regularization) is different from Lasso because it reduce coefficients but without making them zero, which is useful when all features contribute but we have a problem of multicollinearity. The main difference is that Lasso can remove features by setting their coefficients to zero, while Ridge only reduce them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEsLJp7Fo-kl"
   },
   "source": [
    "#15. Train additional algorithms as specified in the attached document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3D1LfRt1pPDJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1mBest Parameters for Models:\u001B[0m\n",
      "RandomForest: {'max_depth': None, 'n_estimators': 100}\n",
      "XGBoost: {'max_depth': 6, 'n_estimators': 100}\n",
      "\n",
      "\u001B[1mEvaluation Results:\u001B[0m\n",
      "\u001B[1mRandomForest (Train Set):\u001B[0m\n",
      "R^2: 0.9051156153532356\n",
      "RMSE: 125.01978132812287\n",
      "MAE: 18.859515634920633\n",
      "MAPE: 17.82390215263994%\n",
      "\n",
      "\u001B[1mRandomForest (Test Set):\u001B[0m\n",
      "R^2: 0.5884615765285028\n",
      "RMSE: 512.8286492405508\n",
      "MAE: 76.37954555555557\n",
      "MAPE: 43.61217361186084%\n",
      "\n",
      "\u001B[1mXGBoost (Train Set):\u001B[0m\n",
      "R^2: 0.9994042101130425\n",
      "RMSE: 9.906675230905652\n",
      "MAE: 6.671878221035004\n",
      "MAPE: 10.630242798542309%\n",
      "\n",
      "\u001B[1mXGBoost (Test Set):\u001B[0m\n",
      "R^2: 0.9478147841117888\n",
      "RMSE: 182.61684129806338\n",
      "MAE: 47.322249774932864\n",
      "MAPE: 38.866065096104776%\n",
      "\n",
      "\u001B[1mHistGradientBoosting (Train Set):\u001B[0m\n",
      "R^2: 0.612137501171583\n",
      "RMSE: 252.76693236955828\n",
      "MAE: 44.39265151047591\n",
      "MAPE: 48.46644863307632%\n",
      "\n",
      "\u001B[1mHistGradientBoosting (Test Set):\u001B[0m\n",
      "R^2: 0.6038877816272085\n",
      "RMSE: 503.12535449286395\n",
      "MAE: 89.18179740800117\n",
      "MAPE: 48.026214667536465%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Define metric function\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (np.abs((y_true - y_pred) / y_true).mean()) * 100\n",
    "    return r2, rmse, mae, mape\n",
    "\n",
    "# Parameter grids for hyperparameter tuning\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6],\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "best_params = {}\n",
    "results = {}\n",
    "\n",
    "# Random Forest with hyperparameter tuning\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=3)\n",
    "rf_grid.fit(X_train_normalized_regression, y_train_regression)\n",
    "best_params[\"RandomForest\"] = rf_grid.best_params_\n",
    "\n",
    "# XGBoost with hyperparameter tuning\n",
    "xgb = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "xgb_grid = GridSearchCV(estimator=xgb, param_grid=xgb_param_grid, cv=3)\n",
    "xgb_grid.fit(X_train_normalized_regression, y_train_regression)\n",
    "best_params[\"XGBoost\"] = xgb_grid.best_params_\n",
    "\n",
    "# HistGradientBoostingRegressor (without GridSearchCV)\n",
    "hist_gb = HistGradientBoostingRegressor(random_state=42)\n",
    "hist_gb.fit(X_train_normalized_regression, y_train_regression)\n",
    "\n",
    "# Dictionary to store models\n",
    "models = {\n",
    "    \"RandomForest\": rf_grid.best_estimator_,\n",
    "    \"XGBoost\": xgb_grid.best_estimator_,\n",
    "    \"HistGradientBoosting\": hist_gb\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "for model_name, model in models.items():\n",
    "    # Train and Test Predictions\n",
    "    y_train_pred_regression = model.predict(X_train_normalized_regression)\n",
    "    y_test_pred_regression = model.predict(X_test_normalized_regression)\n",
    "\n",
    "    # Store metrics\n",
    "    results[f\"{model_name}_train\"] = evaluate_model(y_train_regression, y_train_pred_regression)\n",
    "    results[f\"{model_name}_test\"] = evaluate_model(y_test_regression, y_test_pred_regression)\n",
    "\n",
    "\n",
    "# Evaluate models and print results with custom formatting\n",
    "for model_name, model in models.items():\n",
    "    # Train and Test Predictions\n",
    "    y_train_pred_regression = model.predict(X_train_normalized_regression)\n",
    "    y_test_pred_regression = model.predict(X_test_normalized_regression)\n",
    "\n",
    "    # Store metrics\n",
    "    results[f\"{model_name}_train\"] = evaluate_model(y_train_regression, y_train_pred_regression)\n",
    "    results[f\"{model_name}_test\"] = evaluate_model(y_test_regression, y_test_pred_regression)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"\\n\\033[1mBest Parameters for Models:\\033[0m\")\n",
    "for model, params in best_params.items():\n",
    "    print(f\"{model}: {params}\")\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"\\n\\033[1mEvaluation Results:\\033[0m\")\n",
    "for key, (r2, rmse, mae, mape) in results.items():\n",
    "    model_name = key.split(\"_\")[0]\n",
    "    split = \"Train\" if \"train\" in key else \"Test\"\n",
    "    print(f\"\\033[1m{model_name} ({split} Set):\\033[0m\")\n",
    "    print(f\"R^2: {r2}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MAPE: {mape}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JETnIFoUpXdk"
   },
   "source": [
    "#16. Verbally explain: which model is the best? Briefly explain the model predictions outcome in terms of over and under fitting -explain.\n",
    "#Explain each of the 4 error measuers presented and how they coul be interpreted in the context of your data specifically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjsBNZoxqQVp"
   },
   "source": [
    "#Your answer here: <br>\n",
    "Based on the metrics, XGBoost is the best model, showing high performance on both the training set (R²: 0.9994) and the test set (R²: 0.9478), which indicate a well-fit model with good generalization. Random Forest also performed well but demonstrated more pronounced overfitting, with a high training R² (0.9051) and a much lower R² on the test set (0.5885). HistGradientBoosting showed significant underfitting, with lower R² values for both training (0.6121) and test sets (0.6039), which suggests that it may benefit from more training. <br>\n",
    "\n",
    "1) R² (Coefficient of Determination): This is a metric which indicates how well the model explains the variance in the data. For this data, higher values (close to 1) show better fit like we saw with XGBoost.\n",
    "2) RMSE (Root Mean Squared Error): This is a metric which indicates the standard deviation of prediction errors, with lower values indicating better accuracy. For this data, XGBoost has a RMSE of 182.62 on the test set compared to Random Forest (512.83) and HistGradientBoosting (503.13), which shows a higher accuracy.\n",
    "3) MAE (Mean Absolute Error): This is a metric which gives the average error magnitude. For this data, lower MAE values for XGBoost (47.32) indicate it’s the most accurate on average.\n",
    "4) MAPE (Mean Absolute Percentage Error): This is a metric which shows the average error as a percentage of the actual values, useful for comparing errors across datasets. For this data, XGBoost’s lower MAPE (38.87%) indicates superior predictive accuracy, while HistGradientBoosting’s high MAPE (48.03%) reflects lower accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  * Use of chatgpt:\n",
    "For this project, I used the class notebooks as the primary source for the code and then adapted it to my specific needs with the assistance of ChatGPT. I used ChatGPT to refine and structure the code more effectively, optimize function implementation, and improve the clarity and coherence of my answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Data\n",
    "Regarding the data, I included links to both datasets from Kaggle and organized each dataset into two separate folders named data_for_classification and data_for_regression. Additionally, for the second dataset, I selected a random subset of 1,500 rows, as the original dataset was too large to process in full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M573muOoa6Kp"
   },
   "source": [
    "#Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
